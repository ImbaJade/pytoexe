# -*- coding: utf-8 -*-
"""ARSL PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ybtFHH1_tU4bnZpnp0J0H3YPtNdX5ri4
"""

from google.colab import drive
drive.mount('/content/drive')

from torch._C import *
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from torch.autograd import Variable
import numpy as np
import torch

from typing import List

import csv


class SignLanguageMNIST(Dataset):
     """Sign Language classification dataset.

     Utility for loading Sign Language dataset into PyTorch. Dataset posted on
     Kaggle in 2017, by an unnamed author with username `tecperson`:
     https://www.kaggle.com/datamunge/sign-language-mnist

     Each sample is 1 x 1 x 28 x 28, and each label is a scalar.
     """

     @staticmethod
     def get_label_mapping():
         """
         We map all labels to [0, 23]. This mapping from dataset labels [0, 23]
         to letter indices [0, 25] is returned below.
         """
         mapping = list(range(32))
        # mapping.pop(9)
         return mapping

     @staticmethod
     def read_label_samples_from_csv(path: str):
         """
         Assumes first column in CSV is the label and subsequent 28^2 values
         are image pixel values 0-255.
         """
         mapping = SignLanguageMNIST.get_label_mapping()
         labels, samples = [], []
         with open(path) as f:
             #_ = next(f)  # skip header
             for line in csv.reader(f):
                 label = int(line[0])
                 labels.append(mapping.index(label))
                 samples.append(list(map(int, line[1:])))
         return labels, samples

     def __init__(self,
             path: str="arsl_train.csv",
             mean: List[float]=[0.6434],
             std: List[float]=[0.2482]):
         """
         Args:
             path: Path to `.csv` file containing `label`, `pixel0`, `pixel1`...
         """
         labels, samples = SignLanguageMNIST.read_label_samples_from_csv(path)
         self._samples = np.array(samples, dtype=np.uint8).reshape((-1, 64, 64, 1))
         self._labels = np.array(labels, dtype=np.uint8).reshape((-1, 1))

         self._mean = mean
         self._std = std

     def __len__(self):
         return len(self._labels)

     def __getitem__(self, idx):
         transform = transforms.Compose([
              transforms.ToPILImage(),
              transforms.Resize(64),
              #transforms.CenterCrop(50),
              transforms.RandomHorizontalFlip(),
              transforms.RandomRotation(0.2),
              transforms.ToTensor(),
              transforms.Normalize(mean=self._mean, std=self._std)
             ])

         return {
             'image': transform(self._samples[idx]).float(),
             'label': torch.from_numpy(self._labels[idx]).float()
         }


def get_train_test_loaders(batch_size=32):
     trainset = SignLanguageMNIST('/content/drive/MyDrive/Last/arsl_train.csv')
     trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
     print(len(trainloader))
     testset = SignLanguageMNIST('/content/drive/MyDrive/Last/arsl_test.csv')
     testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)
     print(len(testloader))
     return trainloader, testloader


if __name__ == '__main__':
     loader, _ = get_train_test_loaders(2)
     print(len(loader))
     print(len(next(iter(loader))))

import numpy as np
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch
import torchvision


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, 8)
        self.conv2 = nn.Conv2d(16,32, 8)
        self.conv3 = nn.Conv2d(32, 32,6)
        self.conv4 = nn.Conv2d(32, 32,6)
        self.pool1 = nn.MaxPool2d(3, 1)
        self.pool2 = nn.MaxPool2d(3, 1)
        self.pool3 = nn.MaxPool2d(3, 3)
        self.fc1 = nn.Linear(32*41*41,64)
        self.fc2 = nn.Linear(64, 60)
        self.fc3 = nn.Linear(60,32)


    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(F.relu(self.conv2(x)))
        x = self.pool2(F.relu(self.conv3(x)))
        #print(x.shape)
        x = x.view(-1, 32*41*41)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
def evaluate(outputs: Variable, labels: Variable) -> float:
    """Evaluate neural network outputs against non-one-hotted labels."""
    Y = labels.numpy()
    Yhat = np.argmax(outputs, axis=1)
    return float(np.sum(Yhat == Y))



def main():
    net = Net().float().train()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)

    trainloader, validloader = get_train_test_loaders()
    for i, data in enumerate(trainloader, 0):
        inputs = Variable(data['image'].float())
        img_grad=torchvision.utils.make_grid(inputs)

        break


    for epoch in range(100):  # loop over the dataset multiple times
        train(net, criterion, optimizer, trainloader, epoch,validloader)
        scheduler.step()

    torch.save(net.state_dict(), "/content/arslmodel.pth")


def train(net, criterion, optimizer, trainloader, epoch,validloader):
    running_loss =0.0
    valid_loss = 0.0
    scoreV = scoreT = 0.0
    nT =nV= 0.0
    net.train()
    for i, data in enumerate(trainloader, 0):
        nT +=len(data['image'])
        inputs = Variable(data['image'].float())
        labels = Variable(data['label'].long())
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels[:, 0])
        loss.backward()
        optimizer.step()
        # loss
        running_loss += loss.item()
        # correct
        if isinstance(outputs, torch.Tensor):
            outputs = outputs.detach().numpy()
        scoreT += evaluate(outputs, data['label'][:, 0])

    net.eval()     # Optional when not using Model Specific layer
    for j, data in enumerate(validloader, 0):
        nV+=len(data['image'])
        inputsV = Variable(data['image'].float())
        labelsV = Variable(data['label'].long())
        # Forward Pass
        target = net(inputsV)
        # Find the Loss
        loss = criterion(target,labelsV[:, 0])
        # Calculate Loss
        valid_loss += loss.item()
        # CORRECT
        if isinstance(target, torch.Tensor):
            target = target.detach().numpy()
        scoreV += evaluate(target, data['label'][:, 0])


    print('[%d, %5d] Training_Loss: %.6f  acc_train %.6f' % (epoch, i,  running_loss /nT,(scoreT / nT)*100))
    print('[%d, %5d] Validation_Loss %.6f acc_val %.6f' % (epoch,j,valid_loss / nV,(scoreV / nV)*100))

if __name__ == '__main__':
    main()

from torch._C import *
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from torch.autograd import Variable
import numpy as np
import torch

from typing import List

import csv


class SignLanguageMNIST(Dataset):

     @staticmethod
     def get_label_mapping():
         """
         We map all labels to [0, 23]. This mapping from dataset labels [0, 23]
         to letter indices [0, 25] is returned below.
         """
         mapping = list(range(32))
        # mapping.pop(9)
         return mapping

     @staticmethod
     def read_label_samples_from_csv(path: str):
         """
         Assumes first column in CSV is the label and subsequent 28^2 values
         are image pixel values 0-255.
         """
         mapping = SignLanguageMNIST.get_label_mapping()
         labels, samples = [], []
         with open(path) as f:
             #_ = next(f)  # skip header
             for line in csv.reader(f):
                 label = int(line[0])
                 labels.append(mapping.index(label))
                 samples.append(list(map(int, line[1:])))
         return labels, samples

     def __init__(self,
             path: str="arsl_train.csv",
             mean: List[float]=[0.6434],
             std: List[float]=[0.2482]):
         """
         Args:
             path: Path to `.csv` file containing `label`, `pixel0`, `pixel1`...
         """
         labels, samples = SignLanguageMNIST.read_label_samples_from_csv(path)
         self._samples = np.array(samples, dtype=np.uint8).reshape((-1, 64, 64, 1))
         self._labels = np.array(labels, dtype=np.uint8).reshape((-1, 1))

         self._mean = mean
         self._std = std

     def __len__(self):
         return len(self._labels)

     def __getitem__(self, idx):
         transform = transforms.Compose([
              transforms.ToPILImage(),
              transforms.Resize(64),
              #transforms.CenterCrop(50),
              transforms.RandomHorizontalFlip(),
              transforms.RandomRotation(0.2),
              transforms.ToTensor(),
              transforms.Normalize(mean=self._mean, std=self._std)
             ])

         return {
             'image': transform(self._samples[idx]).float(),
             'label': torch.from_numpy(self._labels[idx]).float()
         }


def get_train_test_loaders(batch_size=32):
  trainset = SignLanguageMNIST('/content/drive/MyDrive/Last/arsl_train.csv')
  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
  print(len(trainloader))
  testset = SignLanguageMNIST('/content/drive/MyDrive/Last/arsl_test.csv')
  testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)
  print(len(testloader))
  return trainloader, testloader

loader, _ = get_train_test_loaders(2)
print(len(loader))
print(len(next(iter(loader))))

import numpy as np
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch
import torchvision
from torch.utils.tensorboard import SummaryWriter

from torch._C import *
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from torch.autograd import Variable
import numpy as np
import torch

from typing import List

import csv


class SignLanguageMNIST(Dataset):

     @staticmethod
     def get_label_mapping():
         """
         We map all labels to [0, 23]. This mapping from dataset labels [0, 23]
         to letter indices [0, 25] is returned below.
         """
         mapping = list(range(32))
        # mapping.pop(9)
         return mapping

     @staticmethod
     def read_label_samples_from_csv(path: str):
         """
         Assumes first column in CSV is the label and subsequent 28^2 values
         are image pixel values 0-255.
         """
         mapping = SignLanguageMNIST.get_label_mapping()
         labels, samples = [], []
         with open(path) as f:
             #_ = next(f)  # skip header
             for line in csv.reader(f):
                 label = int(line[0])
                 labels.append(mapping.index(label))
                 samples.append(list(map(int, line[1:])))
         return labels, samples

     def __init__(self,
             path: str="arsl_train.csv",
             mean: List[float]=[0.6434],
             std: List[float]=[0.2482]):
         """
         Args:
             path: Path to `.csv` file containing `label`, `pixel0`, `pixel1`...
         """
         labels, samples = SignLanguageMNIST.read_label_samples_from_csv(path)
         self._samples = np.array(samples, dtype=np.uint8).reshape((-1, 64, 64, 1))
         self._labels = np.array(labels, dtype=np.uint8).reshape((-1, 1))

         self._mean = mean
         self._std = std

     def __len__(self):
         return len(self._labels)

     def __getitem__(self, idx):
         transform = transforms.Compose([
              transforms.ToPILImage(),
              transforms.Resize(64),
              #transforms.CenterCrop(50),
              transforms.RandomHorizontalFlip(),
              transforms.RandomRotation(0.2),
              transforms.ToTensor(),
              transforms.Normalize(mean=self._mean, std=self._std)
             ])

         return {
             'image': transform(self._samples[idx]).float(),
             'label': torch.from_numpy(self._labels[idx]).float()
         }


def get_train_test_loaders(batch_size=32):
  trainset = SignLanguageMNIST('/content/drive/MyDrive/Last/arsl_train.csv')
  trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)
  print(len(trainloader))
  testset = SignLanguageMNIST('/content/drive/MyDrive/Last/arsl_test.csv')
  testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)
  print(len(testloader))
  return trainloader, testloader

writer = SummaryWriter("arslsummaryba=32_addlayer2_lr=0.0001")
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, 8)
        self.conv2 = nn.Conv2d(16,32, 8)
        self.conv3 = nn.Conv2d(32, 32,6)
        self.conv4 = nn.Conv2d(32, 32,6)
        self.pool1 = nn.MaxPool2d(3, 1)
        self.pool2 = nn.MaxPool2d(3, 1)
        self.pool3 = nn.MaxPool2d(3, 3)
        self.fc1 = nn.Linear(32*41*41,64)
        self.fc2 = nn.Linear(64, 60)
        self.fc3 = nn.Linear(60,32)


    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool1(F.relu(self.conv2(x)))
        x = self.pool2(F.relu(self.conv3(x)))
        #print(x.shape)
        x = x.view(-1, 32*41*41)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
def evaluate(outputs: Variable, labels: Variable) -> float:
    """Evaluate neural network outputs against non-one-hotted labels."""
    Y = labels.numpy()
    Yhat = np.argmax(outputs, axis=1)
    return float(np.sum(Yhat == Y))



def main():
    net = Net().float().train()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)

    trainloader, validloader = get_train_test_loaders()
    for i, data in enumerate(trainloader, 0):
        inputs = Variable(data['image'].float())
        img_grad=torchvision.utils.make_grid(inputs)
        writer.add_image('arsl images',img_grad)
        writer.add_graph(net,inputs)
        break
    writer.close()

    for epoch in range(100):  # loop over the dataset multiple times
        train(net, criterion, optimizer, trainloader, epoch,validloader)
        scheduler.step()
        writer.close()
    torch.save(net.state_dict(), "/content/drive/MyDrive/Last/arslmodelbat32_2lr0.0001.pth")


def train(net, criterion, optimizer, trainloader, epoch,validloader):
    running_loss =0.0
    valid_loss = 0.0
    scoreV = scoreT = 0.0
    nT =nV= 0.0
    net.train()
    for i, data in enumerate(trainloader, 0):
        nT +=len(data['image'])
        inputs = Variable(data['image'].float())
        labels = Variable(data['label'].long())
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels[:, 0])
        loss.backward()
        optimizer.step()
        # loss
        running_loss += loss.item()
        # correct
        if isinstance(outputs, torch.Tensor):
            outputs = outputs.detach().numpy()
        scoreT += evaluate(outputs, data['label'][:, 0])
        # inp = Variable(data['image'].float())
        # img_grad=torchvision.utils.make_grid(inp)
        # writer.add_image('arsl images_train'+str(i),img_grad)
        # writer.close()
    net.eval()     # Optional when not using Model Specific layer
    for j, data in enumerate(validloader, 0):
        nV+=len(data['image'])
        inputsV = Variable(data['image'].float())
        labelsV = Variable(data['label'].long())
        # Forward Pass
        target = net(inputsV)
        # Find the Loss
        loss = criterion(target,labelsV[:, 0])
        # Calculate Loss
        valid_loss += loss.item()
        # CORRECT
        if isinstance(target, torch.Tensor):
            target = target.detach().numpy()
        scoreV += evaluate(target, data['label'][:, 0])
        # inp = Variable(data['image'].float())
        # img_grad=torchvision.utils.make_grid(inp)
        # writer.add_image('arsl images_test'+str(j),img_grad)
        # writer.close()

    print('[%d, %5d] Training_Loss: %.6f  acc_train %.6f' % (epoch, i,  running_loss /nT,(scoreT / nT)*100))
    print('[%d, %5d] Validation_Loss %.6f acc_val %.6f' % (epoch,j,valid_loss / nV,(scoreV / nV)*100))
    writer.add_scalars("RESULTS_ACCURCY", {'ACCURCY_TRIANING':(scoreT/nT)*100,'ACCURCY_VALIDATION':(scoreV / nV)*100})
    writer.add_scalars("RESULTS_LOSS", {'LOSS_TRIANING':running_loss /nT,'LOSS_VALIDATION':valid_loss/nV})
if __name__ == '__main__':
    main()